# ğŸ“Š Latency Tracking & Performance Monitoring

## Overview

The voice bot now includes comprehensive latency tracking that prints detailed timing information for every question and response.

## What Gets Tracked

### 1. **Per-Question Breakdown** â±ï¸

For each question in the qualification flow, you'll see:

- **TTS (Text-to-Speech)**: Time taken to generate and stream bot's question
- **STT (Speech-to-Text)**: Time taken to transcribe user's answer
- **User Think Time**: Time between bot finishing speaking and user responding
- **Total Response Time**: Complete time from question asked to answer received

### 2. **Final Summary Report** ğŸ“Š

After qualification completes, you'll see:

- Table with all questions and their individual timings
- Average times for each metric
- Total session duration
- Performance metrics showing bot processing vs user interaction time

### 3. **Chat Mode Latency** ğŸ’¬

For conversations after qualification:

- LLM processing time
- Total response time including TTS

## Example Output

### Individual Question Breakdown

```
================================================================================
â±ï¸  LATENCY BREAKDOWN - Question 1
================================================================================
â“ Question: Do you own your home?
ğŸ’¬ Answer: yes I do

ğŸ“Š Timing Breakdown:
--------------------------------------------------------------------------------
  ğŸ”Š Text-to-Speech (TTS):     1.85s  (Bot speaking question)
  ğŸ¤ Speech-to-Text (STT):     1.23s  (Transcribing user answer)
  â° Total Response Time:      6.45s  (Question asked â†’ Answer received)
  ğŸ¤” User Think + Speak Time:  5.22s  (After bot finished speaking)
================================================================================
```

### Final Summary

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ“Š FINAL LATENCY SUMMARY                                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Q # â”‚ Question                        â”‚  TTS   â”‚  STT   â”‚ Think  â”‚ Response â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1  â”‚ Do you own your home?           â”‚  1.85s â”‚  1.23s â”‚  5.22s â”‚   6.45s â”‚
â”‚  2  â”‚ Is your budget over $10,000?    â”‚  2.10s â”‚  1.15s â”‚  4.80s â”‚   5.95s â”‚
â”‚  3  â”‚ Are you looking to start wit... â”‚  2.45s â”‚  0.98s â”‚  5.30s â”‚   6.28s â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ AVG â”‚ Average per question            â”‚  2.13s â”‚  1.12s â”‚  5.11s â”‚   6.23s â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ Total Session Duration: 42.35s
ğŸ“ Questions Asked: 3
âš¡ Average Response Time: 6.23s per question
ğŸ”Š Total TTS Time: 6.40s
ğŸ¤ Total STT Time: 3.36s

ğŸ’¡ Performance Metrics:
   â€¢ Bot Processing: 9.76s (23.0% of total)
   â€¢ User Interaction: 32.59s (77.0% of total)

================================================================================
```

### Chat Mode Latency

```
======================================================================
ğŸ’¬ CHAT MODE LATENCY
======================================================================
User: What services do you offer?

ğŸ“Š Processing Times:
----------------------------------------------------------------------
  ğŸ¤– LLM Processing:   3.45s  (Generating response)
  â° Total Time:       5.60s  (Including TTS)
======================================================================
```

## How to Use

### Run the Bot

```bash
venv/bin/python main.py
```

### Watch the Console

All latency information is automatically printed to the console (stdout) as the conversation progresses:

1. **Real-time tracking** - See breakdown after each question
2. **Final summary** - Complete report when qualification ends
3. **Chat tracking** - Individual latencies for each chat interaction

### Analyze Performance

Use the latency data to:

- **Identify bottlenecks**: Which component is slowest?
- **Optimize TTS**: Try different voices or adjust settings
- **Monitor STT**: Check if transcription is taking too long
- **User experience**: Track how long users take to respond
- **System performance**: Compare sessions over time

## Metrics Explained

### TTS (Text-to-Speech)
Time from starting to generate audio until all chunks are sent to client. Includes:
- Edge-TTS API call
- Audio format conversion
- Streaming to WebSocket

### STT (Speech-to-Text)
Time from receiving audio data until transcription is complete. Includes:
- Audio format detection and conversion
- Faster Whisper model inference
- Text extraction

### User Think Time
Time between bot finishing speaking and user starting to answer. Indicates:
- User comprehension time
- Response formulation time
- Actual speaking time

### Total Response Time
Complete cycle from question asked to answer received. Most important metric for user experience.

### LLM Processing (Chat Mode)
Time for Ollama to generate response using Qwen3-Coder model.

## Performance Tips

### Faster TTS
- Use simpler voice models (some accents are faster)
- Reduce text length where possible

### Faster STT
- Use smaller Whisper model: `tiny`, `base`, or `small`
- Ensure good audio quality (reduces retry attempts)

### Faster LLM
- Use smaller/quantized models
- Optimize system prompt
- Enable GPU acceleration if available

## Log Files

Latency information is also logged with timestamps:

```bash
2026-02-17 14:30:23 - voice_stream - INFO - â±ï¸  [TIMING] Response time: 6.45s from question asked
```

Check your console output for the visual tables and complete latency reports!
