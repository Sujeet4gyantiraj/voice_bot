# Piper TTS Implementation

## Overview
Successfully replaced edge-tts with **Piper TTS** - a fast, local, offline neural text-to-speech engine.

## Key Benefits

### ðŸš€ **Performance**
- **Offline**: No internet required, all processing is local
- **Fast**: 5-7 seconds for typical responses (including first-time model download)
- **Cached**: Voice models are loaded once and reused for subsequent requests

### ðŸŽ¯ **Quality**
- **Neural TTS**: High-quality, natural-sounding voices
- **Multiple accents**: US English, UK English voices available
- **Consistent**: Same quality every time, no API rate limits

### ðŸ’¾ **Storage**
- Voice models are downloaded automatically on first use
- Stored in: `~/.local/share/piper-voices/`
- Each model is ~10-20MB (one-time download)

## Available Voices

### Current Mapping (UI Selector â†’ Piper Model)

| UI Voice Selection      | Piper Model                       | Accent/Gender |
|------------------------|-----------------------------------|---------------|
| en-US-AriaNeural       | en_US-lessac-medium              | US Female     |
| en-US-GuyNeural        | en_US-libritts_r-medium          | US Male       |
| en-US-JennyNeural      | en_US-amy-medium                 | US Female     |
| en-US-ChristopherNeural| en_US-libritts_r-medium          | US Male       |
| en-GB-SoniaNeural      | en_GB-alba-medium                | UK Female     |
| en-GB-RyanNeural       | en_GB-northern_english_male-medium| UK Male       |
| en-AU-NatashaNeural    | en_US-amy-medium (fallback)      | US Female     |
| en-AU-WilliamNeural    | en_US-libritts_r-medium (fallback)| US Male       |
| en-IN-NeerjaNeural     | en_US-lessac-medium (fallback)   | US Female     |
| en-IN-PrabhatNeural    | en_US-libritts_r-medium (fallback)| US Male       |
| en-CA-ClaraNeural      | en_US-lessac-medium (fallback)   | US Female     |
| en-CA-LiamNeural       | en_US-libritts_r-medium (fallback)| US Male       |

*Note: Australian, Indian, and Canadian voices fall back to US English models*

## Technical Implementation

### Architecture
```python
from piper import PiperVoice

# Voice models directory
PIPER_MODELS_DIR = Path.home() / ".local" / "share" / "piper-voices"

# Voice cache (loaded models remain in memory)
_voice_cache: Dict[str, PiperVoice] = {}

# Automatic download on first use
def download_voice_if_needed(voice_name: str) -> Path:
    # Downloads .onnx model and .onnx.json config
    # Only downloads if not already cached
```

### TTS Generation Flow
1. **Request**: User selects voice from dropdown
2. **Mapping**: UI voice name mapped to Piper model name
3. **Cache Check**: Check if model already loaded in `_voice_cache`
4. **Download** (if needed): Fetch model from Hugging Face
5. **Load**: Load model with `PiperVoice.load(model_path)`
6. **Synthesize**: Generate WAV audio with `synthesize_wav()`
7. **Format**: Convert to 16kHz, mono, 16-bit WAV
8. **Return**: Send audio bytes to frontend

### Voice Models Source
All models are downloaded from:
```
https://huggingface.co/rhasspy/piper-voices/resolve/v1.0.0/
```

Model structure:
- `en_US-lessac-medium.onnx` - ONNX neural model
- `en_US-lessac-medium.onnx.json` - Configuration file

## Configuration

### Default Voice
```python
DEFAULT_PIPER_VOICE = "en_US-lessac-medium"
```

### Adding New Voices
To add more voices, update `PIPER_VOICES` dictionary in `main.py`:

```python
PIPER_VOICES = {
    "en_US-lessac-medium": "https://huggingface.co/.../en_US-lessac-medium.onnx",
    "YOUR_NEW_VOICE": "https://huggingface.co/.../YOUR_VOICE.onnx",
}
```

Then update `VOICE_MAPPING` to map UI names:
```python
VOICE_MAPPING = {
    "en-US-AriaNeural": "YOUR_NEW_VOICE",
}
```

## Performance Metrics

### Latency Breakdown
```
ðŸ“Š First Generation (includes download & loading):
   - Model Download: 2-3s
   - Model Loading: 1-2s
   - Speech Generation: 2-3s
   - Total: ~6-8s

âš¡ Subsequent Generations (cached):
   - Speech Generation: 2-3s only
   - Total: ~2-3s
```

### Comparison with Edge-TTS

| Metric               | Edge-TTS      | Piper TTS     |
|---------------------|---------------|---------------|
| **Internet Required**| Yes âœ—        | No âœ“          |
| **First Generation** | 2-4s         | 6-8s          |
| **Cached Generation**| 2-4s         | 2-3s          |
| **Voice Quality**    | Excellent    | Excellent     |
| **Rate Limits**      | Yes          | No            |
| **Privacy**          | Cloud        | Local         |
| **Reliability**      | Network-dependent | Always available |

## Testing

### Test Script
```bash
cd /home/sujeet/Downloads/ollama_model/ollama_bot/voice_bot
venv/bin/python3 test_piper.py
```

### Expected Output
```
INFO:piper_test:Testing Piper TTS...
INFO:voice_stream:ðŸ“¥ [TTS] Downloading voice model: en_US-lessac-medium...
INFO:voice_stream:âœ… [TTS] Downloaded en_US-lessac-medium successfully
INFO:voice_stream:âœ… [TTS] Loaded voice model: en_US-lessac-medium
INFO:voice_stream:âœ… [TTS] Generated 168714 bytes in 6.43s
INFO:piper_test:ðŸŽ‰ All tests passed!
```

### Play Generated Audio
```bash
aplay test_piper_output.wav
```

## Dependencies

### Updated requirements.txt
```
fastapi>=0.109.0
uvicorn[standard]>=0.27.0
pydantic>=2.5.0
requests>=2.31.0
websockets>=12.0
faster-whisper>=1.0.0
piper-tts>=1.2.0  # â† Changed from edge-tts
pydub>=0.25.1
python-multipart>=0.0.6
```

### Installation
```bash
venv/bin/pip install piper-tts>=1.2.0
```

## Frontend Integration

### No Changes Required
The frontend dropdown still uses Edge-TTS voice names for backward compatibility. The backend automatically maps them to Piper voices via `VOICE_MAPPING` dictionary.

### Example
```javascript
// Frontend sends:
ws.send(JSON.stringify({
    type: "control",
    action: "set_voice",
    voice: "en-GB-SoniaNeural"
}));

// Backend maps to: en_GB-alba-medium
// User hears UK female voice
```

## Troubleshooting

### Issue: "Import piper could not be resolved"
**Solution**: This is just an IDE warning. The import works fine in the venv.

### Issue: First generation is slow
**Solution**: Expected behavior. Model is being downloaded and loaded. Subsequent requests are much faster.

### Issue: Model download fails
**Solution**: Check internet connection. Models are downloaded from Hugging Face on first use.

### Issue: "voice not found"
**Solution**: Add the voice to `PIPER_VOICES` dictionary with its download URL.

## Future Enhancements

### Possible Improvements
1. **Pre-download**: Download all models on first startup
2. **More accents**: Add Australian, Indian, Canadian native voices
3. **Voice cloning**: Support custom voice models
4. **Streaming**: Generate audio in chunks for lower latency
5. **Speed control**: Add `length_scale` parameter for faster/slower speech

## References

- **Piper TTS**: https://github.com/rhasspy/piper
- **Voice Models**: https://huggingface.co/rhasspy/piper-voices
- **Documentation**: https://github.com/rhasspy/piper/blob/master/README.md
- **Python Package**: https://pypi.org/project/piper-tts/

---

**Implementation Date**: February 17, 2025  
**Version**: 1.0  
**Status**: âœ… Fully Functional
